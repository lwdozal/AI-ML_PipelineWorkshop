{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Environment Test\n",
    "\n",
    "This notebook validates your environment and tests API connectivity before running the full pipeline.\n",
    "\n",
    "**Workshop**: AI/ML Pipeline - Synthetic Data Generation  \n",
    "**Platform**: CyVerse Jupyter Lab PyTorch GPU\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "1. Verifies all required packages are installed\n",
    "2. Tests configuration loading\n",
    "3. Validates API authentication\n",
    "4. Generates a test image\n",
    "5. Estimates costs for different batch sizes\n",
    "6. Provides troubleshooting guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Package Verification\n",
    "\n",
    "First, let's verify all required packages are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]\n",
      "Python executable: c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\ai_workshop2026\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# src_path = os.path.join(os.getcwd(), '..', 'src')\n",
    "\n",
    "# # Insert it at the beginning of the system path\n",
    "# sys.path.insert(0, src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking required packages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lwert\\AppData\\Local\\Temp\\ipykernel_53916\\2184794989.py:22: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  __import__(package)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ google.generativeai\n",
      "  ✓ pandas\n",
      "  ✓ numpy\n",
      "  ✓ PIL\n",
      "  ✓ cv2\n",
      "  ✓ dotenv\n",
      "  ✓ yaml\n",
      "  ✓ tqdm\n",
      "  ✓ matplotlib\n",
      "  ✓ seaborn\n",
      "  ✓ requests\n",
      "  ✓ bs4\n",
      "\n",
      "✓ All required packages are installed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    'google.generativeai',\n",
    "    'pandas',\n",
    "    'numpy',\n",
    "    'PIL',\n",
    "    'cv2',\n",
    "    'dotenv',\n",
    "    'yaml',\n",
    "    'tqdm',\n",
    "    'matplotlib',\n",
    "    'seaborn',\n",
    "    'requests',\n",
    "    'bs4'\n",
    "]\n",
    "\n",
    "print(\"\\nChecking required packages...\")\n",
    "missing_packages = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"  ✓ {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"  ✗ {package} - MISSING\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n⚠ Warning: {len(missing_packages)} packages missing!\")\n",
    "    print(\"Please run: pip install -r requirements.txt\")\n",
    "else:\n",
    "    print(\"\\nAll required packages are installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Custom Modules\n",
    "\n",
    "Import our custom modules from the src/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All custom modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to path\n",
    "parent_dir = Path.cwd().parent\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "try:\n",
    "    from src import config, gemini_client, data_loader, prompt_builder, output_handler, validation\n",
    "    print(\"All custom modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Failed to import custom modules: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Make sure you're running from the notebooks/ directory\")\n",
    "    print(\"2. Verify src/ directory exists with all .py files\")\n",
    "    print(\"3. Check for syntax errors in src modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration Test\n",
    "\n",
    "Test loading configuration from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 18:21:04,333 - src.config - INFO - Logging configured successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded successfully!\n",
      "\n",
      "Configuration: Config(images=50, model=gemini-2.5-flash-image, resolution=1K)\n",
      "\n",
      "Generation Settings:\n",
      "  Number of images: 50\n",
      "  Batch size: 10\n",
      "  Resolution: 1K\n",
      "  Model: gemini-2.5-flash-image\n",
      "\n",
      "Rate Limiting:\n",
      "  Requests/minute: 10\n",
      "  Requests/day: 1000\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load configuration\n",
    "    cfg = config.load_config()\n",
    "    print(\"✓ Configuration loaded successfully!\")\n",
    "    print(f\"\\nConfiguration: {cfg}\")\n",
    "    \n",
    "    # Display key settings\n",
    "    print(\"\\nGeneration Settings:\")\n",
    "    print(f\"  Number of images: {cfg.generation['num_images']}\")\n",
    "    print(f\"  Batch size: {cfg.generation['batch_size']}\")\n",
    "    print(f\"  Resolution: {cfg.generation['resolution']}\")\n",
    "    print(f\"  Model: {cfg.generation['model']}\")\n",
    "    \n",
    "    print(\"\\nRate Limiting:\")\n",
    "    print(f\"  Requests/minute: {cfg.rate_limiting['requests_per_minute']}\")\n",
    "    print(f\"  Requests/day: {cfg.rate_limiting['requests_per_day']}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"✗ Configuration file not found: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    \n",
    "    print(\"1. Verify config/generation_config.yaml exists\")\n",
    "    print(\"2. Check file permissions\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Configuration error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. API Key Validation\n",
    "\n",
    "Check if Google Gemini API key is configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found!\n",
      "  Key preview: AIzaSyAHQN...B2Qs\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    api_key = cfg.api_key\n",
    "    print(\"API key found!\")\n",
    "    print(f\"  Key preview: {api_key[:10]}...{api_key[-4:]}\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"✗ API key not found: {e}\")\n",
    "    print(\"\\nSetup Instructions:\")\n",
    "    print(\"1. Get your API key from: https://makersuite.google.com/app/apikey\")\n",
    "    print(\"2. Copy config/.env.example to config/.env\")\n",
    "    print(\"3. Add your API key to config/.env: GOOGLE_API_KEY=your_key_here\")\n",
    "    print(\"4. Restart this notebook\")\n",
    "    \n",
    "    # Stop execution if no API key\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. API Connection Test\n",
    "\n",
    "Test connection to Google Gemini API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing API connection...\n",
      "\n",
      "✓ Successfully connected to Gemini API!\n",
      "  Available models: 53\n",
      "  ✓ Target model 'gemini-2.5-flash-image' is available\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "try:\n",
    "    # Configure API\n",
    "    genai.configure(api_key=cfg.api_key)\n",
    "    \n",
    "    # List available models\n",
    "    print(\"Testing API connection...\")\n",
    "    models = [m.name for m in genai.list_models()]\n",
    "    \n",
    "    print(\"\\n✓ Successfully connected to Gemini API!\")\n",
    "    print(f\"  Available models: {len(models)}\")\n",
    "    \n",
    "    # Check if our model is available\n",
    "    target_model = cfg.generation['model']\n",
    "    if any(target_model in m for m in models):\n",
    "        print(f\"  ✓ Target model '{target_model}' is available\")\n",
    "    else:\n",
    "        print(f\"  Warning: Target model '{target_model}' not found in available models\")\n",
    "        print(f\"  Available image models: {[m for m in models if 'image' in m.lower()]}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"API connection failed: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Verify your API key is correct\")\n",
    "    print(\"2. Check your internet connection\")\n",
    "    print(\"3. Ensure you have API access enabled\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Test Image\n",
    "\n",
    "Generate a single test image to verify everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 18:21:33,339 - src.gemini_client - INFO - Gemini API client initialized\n",
      "2026-01-21 18:21:33,343 - src.gemini_client - INFO - Initialized gemini-2.5-flash-image for image generation\n",
      "2026-01-21 18:21:33,350 - src.gemini_client - INFO - Generating image with prompt length: 173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test image...\n",
      "(This may take 10-30 seconds)\n",
      "\n",
      "Test prompt: Photorealistic image of a peaceful civic gathering in an urban setting. Diverse crowd of people holding signs, organized demonstration, clear daytime lighting, high quality.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 18:21:33,570 - src.gemini_client - WARNING - Request failed (attempt 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "Please retry in 26.541605749s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2026-01-21 18:21:33,576 - src.gemini_client - INFO - Retrying in 2.0s\n",
      "2026-01-21 18:21:35,688 - src.gemini_client - WARNING - Request failed (attempt 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "Please retry in 24.428137906s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2026-01-21 18:21:35,690 - src.gemini_client - INFO - Retrying in 4.0s\n",
      "2026-01-21 18:21:39,797 - src.gemini_client - WARNING - Request failed (attempt 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "Please retry in 20.31769879s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 20\n",
      "}\n",
      "]\n",
      "2026-01-21 18:21:39,800 - src.gemini_client - ERROR - All retry attempts failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "Please retry in 20.31769879s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 20\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✗ Image generation failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-flash-preview-image\n",
      "Please retry in 20.31769879s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-preview-image\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 20\n",
      "}\n",
      "]\n",
      "\n",
      "Troubleshooting:\n",
      "1. Check API quota limits\n",
      "2. Verify model name is correct\n",
      "3. Try a simpler prompt\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-flash-preview-image\nPlease retry in 20.31769879s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash-preview-image\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash-preview-image\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash-preview-image\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 20\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Generate image\u001b[39;00m\n\u001b[32m     32\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m result = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m elapsed = time.time() - start_time\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✓ Test image generated successfully in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\src\\gemini_client.py:233\u001b[39m, in \u001b[36mGeminiImageGenerator.generate_image\u001b[39m\u001b[34m(self, prompt, output_path)\u001b[39m\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# Make request with retry logic\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Extract image data\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response.parts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\src\\gemini_client.py:168\u001b[39m, in \u001b[36mGeminiClient._make_request_with_retry\u001b[39m\u001b[34m(self, request_func, *args, **kwargs)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# All retries failed\u001b[39;00m\n\u001b[32m    167\u001b[39m logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAll retry attempts failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m last_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\src\\gemini_client.py:150\u001b[39m, in \u001b[36mGeminiClient._make_request_with_retry\u001b[39m\u001b[34m(self, request_func, *args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28mself\u001b[39m.rate_limiter.wait_if_needed()\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# Make request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m response = \u001b[43mrequest_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# Record successful request\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;28mself\u001b[39m.rate_limiter.record_request()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\src\\gemini_client.py:222\u001b[39m, in \u001b[36mGeminiImageGenerator.generate_image.<locals>._generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\ai_workshop2026\\Lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\ai_workshop2026\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\ai_workshop2026\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\ai_workshop2026\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\ai_workshop2026\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\ai_workshop2026\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\ai_workshop2026\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\ai_workshop2026\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\ai_workshop2026\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:77\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-flash-preview-image\nPlease retry in 20.31769879s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash-preview-image\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash-preview-image\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash-preview-image\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 20\n}\n]"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "print(\"Generating test image...\")\n",
    "print(\"(This may take 10-30 seconds)\\n\")\n",
    "\n",
    "try:\n",
    "    # Initialize rate limiter\n",
    "    rate_limiter = gemini_client.RateLimiter(\n",
    "        requests_per_minute=cfg.rate_limiting['requests_per_minute'],\n",
    "        requests_per_day=cfg.rate_limiting['requests_per_day']\n",
    "    )\n",
    "    \n",
    "    # Initialize image generator\n",
    "    generator = gemini_client.GeminiImageGenerator(\n",
    "        api_key=cfg.api_key,\n",
    "        rate_limiter=rate_limiter,\n",
    "        model=cfg.generation['model'],\n",
    "        resolution=cfg.generation['resolution']\n",
    "    )\n",
    "    \n",
    "    # Simple test prompt\n",
    "    test_prompt = (\n",
    "        \"Photorealistic image of a peaceful civic gathering in an urban setting. \"\n",
    "        \"Diverse crowd of people holding signs, organized demonstration, \"\n",
    "        \"clear daytime lighting, high quality.\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Test prompt: {test_prompt}\\n\")\n",
    "    \n",
    "    # Generate image\n",
    "    start_time = time.time()\n",
    "    result = generator.generate_image(test_prompt)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n✓ Test image generated successfully in {elapsed:.1f}s!\")\n",
    "    print(f\"  Image size: {result['metadata']['image_size']}\")\n",
    "    print(f\"  Image mode: {result['metadata']['image_mode']}\")\n",
    "    \n",
    "    # Display image\n",
    "    print(\"\\nGenerated Image:\")\n",
    "    display(result['image'])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Image generation failed: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Check API quota limits\")\n",
    "    print(\"2. Verify model name is correct\")\n",
    "    print(\"3. Try a simpler prompt\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cost Estimation\n",
    "\n",
    "Estimate costs for different batch sizes before running the full pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Estimation for Different Batch Sizes\n",
      "================================================================================\n",
      " Images Resolution  Image Gen  Captions  Labels  Comments  Total (USD)\n",
      "     10         1K       0.01     0.001   0.001     0.005        0.017\n",
      "     20         1K       0.02     0.002   0.002     0.010        0.034\n",
      "     50         1K       0.05     0.005   0.005     0.025        0.085\n",
      "    100         1K       0.10     0.010   0.010     0.050        0.170\n",
      "    200         1K       0.20     0.020   0.020     0.100        0.340\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Notes:\n",
      "- Costs are estimates based on current Gemini API pricing\n",
      "- Actual costs may vary based on prompt complexity and API changes\n",
      "- Free tier has usage limits - start with smaller batches\n",
      "\n",
      "Recommendation: Start with 10-20 images for testing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Cost Estimation for Different Batch Sizes\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test different image counts\n",
    "test_counts = [10, 20, 50, 100, 200]\n",
    "estimates = []\n",
    "\n",
    "for count in test_counts:\n",
    "    # Temporarily set count\n",
    "    cfg.set('generation.num_images', count)\n",
    "    cost_est = cfg.estimate_cost()\n",
    "    estimates.append(cost_est)\n",
    "\n",
    "# Create comparison table\n",
    "df = pd.DataFrame(estimates)\n",
    "df = df[['num_images', 'resolution', 'image_generation', 'captions', 'labels', 'comments', 'total_estimated']]\n",
    "df.columns = ['Images', 'Resolution', 'Image Gen', 'Captions', 'Labels', 'Comments', 'Total (USD)']\n",
    "\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nNotes:\")\n",
    "print(\"- Costs are estimates based on current Gemini API pricing\")\n",
    "print(\"- Actual costs may vary based on prompt complexity and API changes\")\n",
    "print(\"- Free tier has usage limits - start with smaller batches\")\n",
    "print(\"\\nRecommendation: Start with 10-20 images for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Directory Structure Check\n",
    "\n",
    "Verify all output directories are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 18:24:00,166 - src.config - INFO - Loaded environment variables from c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\config\\.env\n",
      "2026-01-21 18:24:00,202 - src.config - INFO - Loaded configuration from c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\config\\generation_config.yaml\n",
      "2026-01-21 18:24:00,211 - src.config - INFO - Logging configured successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking directory structure...\n",
      "\n",
      "✓ Output: c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\data\\generated\n",
      "✓ Images: c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\data\\generated\\images\n",
      "✓ Captions: c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\data\\generated\\captions\n",
      "✓ Labels: c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\data\\generated\\labels\n",
      "✓ Comments: c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\data\\generated\\comments\n",
      "✓ Metadata: c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\data\\generated\\metadata\n",
      "✓ Raw Data: c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\data\\raw\n",
      "✓ QA: c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\data\\..\\qa\n",
      "\n",
      "✓ Directory structure ready!\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking directory structure...\\n\")\n",
    "\n",
    "# Reset configuration\n",
    "cfg = config.load_config()\n",
    "\n",
    "# Check directories\n",
    "directories = {\n",
    "    'Output': cfg.get_output_path(),\n",
    "    'Images': cfg.get_output_path('images'),\n",
    "    'Captions': cfg.get_output_path('captions'),\n",
    "    'Labels': cfg.get_output_path('labels'),\n",
    "    'Comments': cfg.get_output_path('comments'),\n",
    "    'Metadata': cfg.get_output_path('metadata'),\n",
    "    'Raw Data': cfg.get_data_path('raw'),\n",
    "    'QA': cfg.get_data_path('../qa')\n",
    "}\n",
    "\n",
    "for name, path in directories.items():\n",
    "    exists = path.exists()\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"{status} {name}: {path}\")\n",
    "\n",
    "print(\"\\n✓ Directory structure ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. System Summary\n",
    "\n",
    "Complete system check summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENVIRONMENT SETUP COMPLETE\n",
      "================================================================================\n",
      "\n",
      "✓ Python packages installed\n",
      "✓ Custom modules imported\n",
      "✓ Configuration loaded\n",
      "✓ API key configured\n",
      "✓ API connection tested\n",
      "✓ Test image generated\n",
      "✓ Directory structure ready\n",
      "\n",
      "================================================================================\n",
      "NEXT STEPS\n",
      "================================================================================\n",
      "\n",
      "1. Run notebook 02_prepare_source_data.ipynb to fetch source data\n",
      "2. Run notebook 03_generate_images.ipynb to generate synthetic images\n",
      "3. Run notebook 04_generate_metadata.ipynb for captions/labels/comments\n",
      "4. Run notebook 05_quality_assurance.ipynb for QA checks\n",
      "\n",
      "💡 Tip: Start with a small batch (10-20 images) to test the full pipeline\n",
      "   You can increase the num_images in config/generation_config.yaml later\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ENVIRONMENT SETUP COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n✓ Python packages installed\")\n",
    "print(\"✓ Custom modules imported\")\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(\"✓ API key configured\")\n",
    "print(\"✓ API connection tested\")\n",
    "print(\"✓ Test image generated\")\n",
    "print(\"✓ Directory structure ready\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. Run notebook 02_prepare_source_data.ipynb to fetch source data\")\n",
    "print(\"2. Run notebook 03_generate_images.ipynb to generate synthetic images\")\n",
    "print(\"3. Run notebook 04_generate_metadata.ipynb for captions/labels/comments\")\n",
    "print(\"4. Run notebook 05_quality_assurance.ipynb for QA checks\")\n",
    "\n",
    "print(\"\\n💡 Tip: Start with a small batch (10-20 images) to test the full pipeline\")\n",
    "print(\"   You can increase the num_images in config/generation_config.yaml later\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Guide\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**1. ModuleNotFoundError**\n",
    "- Run: `pip install -r requirements.txt` from the project root\n",
    "- Ensure you're using the correct Python environment\n",
    "\n",
    "**2. API Key Error**\n",
    "- Get API key from: https://makersuite.google.com/app/apikey\n",
    "- Copy config/.env.example to config/.env\n",
    "- Add your key: GOOGLE_API_KEY=your_key_here\n",
    "\n",
    "**3. API Connection Failed**\n",
    "- Check internet connection\n",
    "- Verify API key is correct\n",
    "- Check API quota limits\n",
    "\n",
    "**4. Image Generation Timeout**\n",
    "- Increase timeout in rate limiter settings\n",
    "- Check API status: https://status.openai.com/\n",
    "- Try simpler prompts\n",
    "\n",
    "**5. Out of Memory**\n",
    "- Reduce batch size in config\n",
    "- Close other applications\n",
    "- Restart Jupyter kernel\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "- Workshop support: Contact instructors\n",
    "- Documentation: Check README.md and CLAUDE.md\n",
    "- CyVerse support: https://cyverse.org/support"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_workshop2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
