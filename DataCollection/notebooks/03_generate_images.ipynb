{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic Images\n",
    "\n",
    "This notebook generates synthetic social movement images using Google Gemini API, combining data from Atropia, World Bank demographics, and visual references.\n",
    "\n",
    "**Workshop**: AI/ML Pipeline - Synthetic Data Generation  \n",
    "**Date**: January 23, 2026  \n",
    "**Platform**: CyVerse Jupyter Lab PyTorch GPU\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "1. Load configuration and source data\n",
    "2. Initialize API client with rate limiting\n",
    "3. Build prompts from combined data sources\n",
    "4. Generate images in batches with checkpoints\n",
    "5. Save images and metadata\n",
    "6. Summarize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\src\\gemini_client.py:12: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported successfully\n",
      "  Working directory: c:\\Users\\lwert\\OneDrive - University of Arizona\\Documents\\Fellowships\\Jetstream\\AI-ML_PipelineWorkshop\\DataCollection\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add parent directory to path\n",
    "parent_dir = Path.cwd().parent\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from src import config, gemini_client, data_loader, prompt_builder, output_handler\n",
    "\n",
    "print(\"All modules imported successfully\")\n",
    "print(f\"  Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration\n",
    "\n",
    "Review and adjust generation parameters if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 18:15:54,042 - src.config - INFO - Logging configured successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Configuration:\n",
      "================================================================================\n",
      "\n",
      "Images to generate: 50\n",
      "Batch size: 10\n",
      "Resolution: 1K\n",
      "Model: gemini-2.5-flash-image\n",
      "\n",
      "Prompt style: realistic\n",
      "Prompt complexity: medium\n",
      "\n",
      "Rate limit: 10 requests/minute\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "cfg = config.load_config()\n",
    "\n",
    "print(\"Current Configuration:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nImages to generate: {cfg.generation['num_images']}\")\n",
    "print(f\"Batch size: {cfg.generation['batch_size']}\")\n",
    "print(f\"Resolution: {cfg.generation['resolution']}\")\n",
    "print(f\"Model: {cfg.generation['model']}\")\n",
    "print(f\"\\nPrompt style: {cfg.prompts['style']}\")\n",
    "print(f\"Prompt complexity: {cfg.prompts['complexity']}\")\n",
    "print(f\"\\nRate limit: {cfg.rate_limiting['requests_per_minute']} requests/minute\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Settings (Optional)\n",
    "\n",
    "You can modify settings here if needed. Otherwise, skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Adjust number of images\n",
    "# cfg.set('generation.num_images', 20)  # Change to desired number\n",
    "\n",
    "# OPTIONAL: Adjust batch size\n",
    "# cfg.set('generation.batch_size', 5)  # Smaller batches for testing\n",
    "\n",
    "print(\"Settings adjusted (if any changes made above)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Estimation\n",
    "\n",
    "Review estimated costs before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_estimate = cfg.estimate_cost()\n",
    "\n",
    "print(\"Cost Estimation:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nNumber of images: {cost_estimate['num_images']}\")\n",
    "print(f\"Resolution: {cost_estimate['resolution']}\")\n",
    "print(f\"\\nEstimated Costs (USD):\")\n",
    "print(f\"  Image generation: ${cost_estimate['image_generation']:.4f}\")\n",
    "print(f\"  Captions: ${cost_estimate['captions']:.4f}\")\n",
    "print(f\"  Labels: ${cost_estimate['labels']:.4f}\")\n",
    "print(f\"  Comments: ${cost_estimate['comments']:.4f}\")\n",
    "print(f\"\\n  TOTAL: ${cost_estimate['total_estimated']:.4f}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nNote: Actual costs may vary. These are estimates based on typical usage.\")\n",
    "print(\"Free tier limits apply - start with small batches to avoid quota issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Source Data\n",
    "\n",
    "Load data from all three sources: Atropia, World Bank, and social media references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading source data...\\n\")\n",
    "\n",
    "data_dir = cfg.get_data_path('raw')\n",
    "\n",
    "# Initialize data loaders\n",
    "atropia_loader = data_loader.AtropiaDataLoader(data_dir=data_dir)\n",
    "worldbank_loader = data_loader.WorldBankDataLoader(data_dir=data_dir)\n",
    "socialmedia_loader = data_loader.SocialMediaDataLoader(data_dir=data_dir)\n",
    "\n",
    "# Load data\n",
    "atropia_data = atropia_loader.load_data()\n",
    "print(f\"✓ Loaded {len(atropia_data)} Atropia samples\")\n",
    "\n",
    "worldbank_data = worldbank_loader.load_data()\n",
    "print(f\"✓ Loaded {len(worldbank_data)} World Bank profiles\")\n",
    "\n",
    "socialmedia_data = socialmedia_loader.load_descriptions()\n",
    "print(f\"✓ Loaded {len(socialmedia_data)} visual references\")\n",
    "\n",
    "# Initialize combiner\n",
    "combiner = data_loader.DataCombiner(\n",
    "    atropia_loader=atropia_loader,\n",
    "    worldbank_loader=worldbank_loader,\n",
    "    socialmedia_loader=socialmedia_loader\n",
    ")\n",
    "\n",
    "print(\"\\n✓ All source data loaded and ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Prompts\n",
    "\n",
    "Generate prompts by combining data from all sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building prompts...\\n\")\n",
    "\n",
    "# Initialize prompt builder\n",
    "builder = prompt_builder.PromptBuilder(\n",
    "    style=cfg.prompts['style'],\n",
    "    complexity=cfg.prompts['complexity'],\n",
    "    include_temporal=cfg.prompts['include_temporal_context'],\n",
    "    include_demographics=cfg.prompts['include_demographics'],\n",
    "    themes=cfg.prompts['themes'],\n",
    "    settings=cfg.prompts['settings']\n",
    ")\n",
    "\n",
    "# Generate combined data samples\n",
    "num_images = cfg.generation['num_images']\n",
    "combined_samples = combiner.sample_combined(n=num_images)\n",
    "\n",
    "# Build prompts\n",
    "prompts_data = builder.build_batch_prompts(combined_samples)\n",
    "\n",
    "print(f\"✓ Built {len(prompts_data)} prompts\")\n",
    "print(f\"  Style: {cfg.prompts['style']}\")\n",
    "print(f\"  Complexity: {cfg.prompts['complexity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Sample Prompts\n",
    "\n",
    "Let's review a few prompts before generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample Prompts:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(min(3, len(prompts_data))):\n",
    "    prompt_info = prompts_data[i]\n",
    "    print(f\"\\nPrompt {i+1}:\")\n",
    "    print(f\"  {prompt_info['prompt'][:200]}...\")\n",
    "    print(f\"\\n  Source - Theme: {prompt_info['source_data']['atropia']['theme']}\")\n",
    "    print(f\"  Source - Demographics: Age {prompt_info['source_data']['demographics']['age_group']}, \"\n",
    "          f\"{prompt_info['source_data']['demographics']['occupation']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Generation Pipeline\n",
    "\n",
    "Set up API client, rate limiter, and output handler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing generation pipeline...\\n\")\n",
    "\n",
    "# Initialize rate limiter\n",
    "rate_limiter = gemini_client.RateLimiter(\n",
    "    requests_per_minute=cfg.rate_limiting['requests_per_minute'],\n",
    "    requests_per_day=cfg.rate_limiting['requests_per_day'],\n",
    "    enable_backoff=cfg.rate_limiting['enable_exponential_backoff'],\n",
    "    initial_delay=cfg.rate_limiting['initial_retry_delay'],\n",
    "    backoff_multiplier=cfg.rate_limiting['backoff_multiplier'],\n",
    "    max_retries=cfg.rate_limiting['max_retries']\n",
    ")\n",
    "print(\"✓ Rate limiter initialized\")\n",
    "\n",
    "# Initialize image generator\n",
    "generator = gemini_client.GeminiImageGenerator(\n",
    "    api_key=cfg.api_key,\n",
    "    rate_limiter=rate_limiter,\n",
    "    model=cfg.generation['model'],\n",
    "    resolution=cfg.generation['resolution'],\n",
    "    aspect_ratio=cfg.generation['aspect_ratio']\n",
    ")\n",
    "print(f\"✓ Image generator initialized (model: {cfg.generation['model']})\")\n",
    "\n",
    "# Initialize output handler\n",
    "output_dir = cfg.get_output_path()\n",
    "handler = output_handler.OutputHandler(\n",
    "    output_dir=output_dir,\n",
    "    image_format=cfg.output['image_format'],\n",
    "    metadata_format=cfg.output['metadata_format'],\n",
    "    export_csv=cfg.output['export_csv_summaries'],\n",
    "    date_organized=cfg.output['date_organized']\n",
    ")\n",
    "print(f\"✓ Output handler initialized (output: {output_dir})\")\n",
    "\n",
    "# Initialize checkpoint manager\n",
    "checkpoint_path = parent_dir / cfg.generation['checkpoint_file']\n",
    "checkpoint_mgr = gemini_client.CheckpointManager(checkpoint_path)\n",
    "print(f\"✓ Checkpoint manager initialized\")\n",
    "\n",
    "print(\"\\n✓ Pipeline ready to generate images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check for Resume\n",
    "\n",
    "Check if there's a previous interrupted generation to resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for existing checkpoint\n",
    "checkpoint = checkpoint_mgr.load_checkpoint()\n",
    "\n",
    "if checkpoint:\n",
    "    print(\"Found existing checkpoint!\")\n",
    "    print(f\"  Completed: {checkpoint.get('completed', 0)}/{checkpoint.get('total', 0)} images\")\n",
    "    print(f\"  Last checkpoint: {checkpoint.get('timestamp', 'unknown')}\")\n",
    "    \n",
    "    # Ask user if they want to resume\n",
    "    print(\"\\n⚠ Set RESUME = True in the next cell to continue, or False to start fresh\")\n",
    "else:\n",
    "    print(\"No existing checkpoint found. Starting fresh generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True to resume from checkpoint, False to start fresh\n",
    "RESUME = False\n",
    "\n",
    "if RESUME and checkpoint:\n",
    "    start_index = checkpoint.get('completed', 0)\n",
    "    print(f\"Resuming from image {start_index + 1}\")\n",
    "else:\n",
    "    start_index = 0\n",
    "    checkpoint_mgr.clear_checkpoint()\n",
    "    print(\"Starting fresh generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Images\n",
    "\n",
    "Main generation loop with progress tracking and checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING IMAGE GENERATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Generation tracking\n",
    "batch_size = cfg.generation['batch_size']\n",
    "total_images = len(prompts_data)\n",
    "generated_count = start_index\n",
    "error_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"\\nGenerating {total_images - start_index} images in batches of {batch_size}\")\n",
    "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nProgress:\")\n",
    "\n",
    "# Main generation loop\n",
    "for i in tqdm(range(start_index, total_images), initial=start_index, total=total_images):\n",
    "    try:\n",
    "        prompt_data = prompts_data[i]\n",
    "        \n",
    "        # Generate image\n",
    "        result = generator.generate_image(prompt_data['prompt'])\n",
    "        \n",
    "        # Save image and metadata\n",
    "        image_path = handler.save_image(\n",
    "            image=result['image'],\n",
    "            index=i + 1,\n",
    "            prompt_data=prompt_data\n",
    "        )\n",
    "        \n",
    "        generated_count += 1\n",
    "        \n",
    "        # Display latest image (every 5 images)\n",
    "        if (i + 1) % 5 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"\\nProgress: {generated_count}/{total_images} images\")\n",
    "            print(f\"Latest image: {image_path.name}\")\n",
    "            display(result['image'].resize((256, 256)))  # Display smaller preview\n",
    "        \n",
    "        # Save checkpoint after each batch\n",
    "        if (i + 1) % batch_size == 0:\n",
    "            checkpoint_data = {\n",
    "                'completed': generated_count,\n",
    "                'total': total_images,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'last_index': i\n",
    "            }\n",
    "            checkpoint_mgr.save_checkpoint(checkpoint_data)\n",
    "            print(f\"\\n✓ Checkpoint saved: {generated_count}/{total_images} images\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_count += 1\n",
    "        print(f\"\\n✗ Error generating image {i+1}: {e}\")\n",
    "        \n",
    "        # Continue with next image\n",
    "        continue\n",
    "\n",
    "# Final statistics\n",
    "elapsed_time = time.time() - start_time\n",
    "minutes = int(elapsed_time // 60)\n",
    "seconds = int(elapsed_time % 60)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATION COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSuccessfully generated: {generated_count} images\")\n",
    "print(f\"Errors encountered: {error_count}\")\n",
    "print(f\"Total time: {minutes}m {seconds}s\")\n",
    "print(f\"Average time per image: {elapsed_time/generated_count:.1f}s\")\n",
    "\n",
    "# Clear checkpoint on successful completion\n",
    "if error_count == 0:\n",
    "    checkpoint_mgr.clear_checkpoint()\n",
    "    print(\"\\n✓ Checkpoint cleared (generation completed successfully)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Generation Log\n",
    "\n",
    "Save complete generation log for record keeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save generation log\n",
    "log_path = handler.save_generation_log()\n",
    "print(f\"✓ Generation log saved to: {log_path}\")\n",
    "\n",
    "# Get and display summary\n",
    "summary = handler.get_summary()\n",
    "\n",
    "print(\"\\nGeneration Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Output directory: {summary['output_directory']}\")\n",
    "print(f\"Images saved: {summary['images_saved']}\")\n",
    "print(f\"Image format: {summary['image_format']}\")\n",
    "print(f\"\\nDirectory structure:\")\n",
    "for name, path in summary['directories'].items():\n",
    "    print(f\"  {name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Preview Generated Images\n",
    "\n",
    "Display a few random samples from the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get all generated images\n",
    "image_files = list(handler.images_dir.glob(f\"*.{cfg.output['image_format']}\"))\n",
    "\n",
    "if image_files:\n",
    "    # Sample 6 random images\n",
    "    sample_files = random.sample(image_files, min(6, len(image_files)))\n",
    "    \n",
    "    # Display in grid\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Sample Generated Images', fontsize=16)\n",
    "    \n",
    "    for idx, image_file in enumerate(sample_files):\n",
    "        row = idx // 3\n",
    "        col = idx % 3\n",
    "        \n",
    "        img = Image.open(image_file)\n",
    "        axes[row, col].imshow(img)\n",
    "        axes[row, col].set_title(image_file.name)\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images found to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Images have been generated successfully! Continue with:\n",
    "\n",
    "1. **Generate Metadata**: Run notebook `04_generate_metadata.ipynb` to create captions, labels, and comments\n",
    "2. **Quality Assurance**: Run notebook `05_quality_assurance.ipynb` to validate the dataset\n",
    "\n",
    "Your generated images are saved in: `data/generated/images/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_workshop2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
