{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Assurance and Validation\n",
    "\n",
    "This notebook performs comprehensive quality assurance checks on the generated synthetic dataset.\n",
    "\n",
    "**Workshop**: AI/ML Pipeline - Synthetic Data Generation  \n",
    "**Date**: January 23, 2026  \n",
    "**Platform**: CyVerse Jupyter Lab PyTorch GPU\n",
    "\n",
    "## QA Checklist\n",
    "\n",
    "1. **Image Validation**: Verify all images are valid and readable\n",
    "2. **Metadata Completeness**: Check all images have captions, labels, comments\n",
    "3. **Duplicate Detection**: Identify potentially duplicate images\n",
    "4. **Label Distribution Analysis**: Check for bias in labels\n",
    "5. **Human Review Interface**: Sample random images for manual inspection\n",
    "6. **QA Report Generation**: Create comprehensive quality report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from collections import Counter\n",
    "\n",
    "# Add parent directory to path\n",
    "parent_dir = Path.cwd().parent\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from src import config, output_handler, validation\n",
    "\n",
    "print(\"✓ All modules imported successfully\")\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "cfg = config.load_config()\n",
    "\n",
    "# Initialize output handler\n",
    "output_dir = cfg.get_output_path()\n",
    "handler = output_handler.OutputHandler(\n",
    "    output_dir=output_dir,\n",
    "    image_format=cfg.output['image_format']\n",
    ")\n",
    "\n",
    "# Get dataset summary\n",
    "summary = handler.get_summary()\n",
    "\n",
    "print(\"Dataset Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Output directory: {summary['output_directory']}\")\n",
    "print(f\"Images: {summary['images_saved']}\")\n",
    "print(f\"Captions: {summary['captions_saved']}\")\n",
    "print(f\"Labels: {summary['labels_saved']}\")\n",
    "print(f\"Comments: {summary['comments_saved']}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Automated Validation\n",
    "\n",
    "Run comprehensive automated validation checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running automated validation...\\n\")\n",
    "\n",
    "# Initialize dataset validator\n",
    "validator = validation.DatasetValidator(\n",
    "    output_dir=output_dir,\n",
    "    min_image_size_kb=cfg.validation.get('min_image_size_kb', 10),\n",
    "    duplicate_threshold=cfg.validation.get('duplicate_threshold', 95)\n",
    ")\n",
    "\n",
    "# Run validation\n",
    "validation_report = validator.validate_dataset()\n",
    "\n",
    "print(\"✓ Validation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = validation_report['summary']\n",
    "\n",
    "print(\"Validation Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal Images: {summary_data['total_images']}\")\n",
    "print(f\"Valid Images: {summary_data['valid_images']}\")\n",
    "print(f\"Validation Rate: {summary_data['validation_rate']:.1f}%\")\n",
    "print(f\"\\nMetadata Completeness:\")\n",
    "print(f\"  Metadata: {'✓ Complete' if summary_data['metadata_complete'] else '✗ Incomplete'}\")\n",
    "print(f\"  Captions: {'✓ Complete' if summary_data['captions_complete'] else '✗ Incomplete'}\")\n",
    "print(f\"  Labels: {'✓ Complete' if summary_data['labels_complete'] else '✗ Incomplete'}\")\n",
    "print(f\"  Comments: {'✓ Complete' if summary_data['comments_complete'] else '✗ Incomplete'}\")\n",
    "print(f\"\\nDuplicate Detection:\")\n",
    "print(f\"  Duplicates Found: {summary_data['duplicates_found']}\")\n",
    "print(f\"\\nOverall Quality: {summary_data['dataset_quality']}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Validation Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_report = validation_report['images']\n",
    "\n",
    "print(f\"\\nImage Validation Details:\")\n",
    "print(f\"  Total: {images_report['total_images']}\")\n",
    "print(f\"  Valid: {images_report['valid_images']}\")\n",
    "print(f\"  Invalid: {images_report['invalid_images']}\")\n",
    "print(f\"  Rate: {images_report['validation_rate']:.1f}%\")\n",
    "\n",
    "# Show any invalid images\n",
    "if images_report['invalid_images'] > 0:\n",
    "    print(\"\\n⚠ Invalid Images:\")\n",
    "    for result in images_report['results']:\n",
    "        if not result['valid']:\n",
    "            print(f\"  - {Path(result['file_path']).name}: {', '.join(result['issues'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = validation_report['duplicates']\n",
    "\n",
    "print(f\"\\nDuplicate Detection:\")\n",
    "print(f\"  Number of duplicate pairs: {duplicates['num_duplicates']}\")\n",
    "\n",
    "if duplicates['num_duplicates'] > 0:\n",
    "    print(\"\\n⚠ Potential Duplicates:\")\n",
    "    for img1, img2, similarity in duplicates['duplicate_pairs'][:10]:  # Show first 10\n",
    "        print(f\"  - {Path(img1).name} ↔ {Path(img2).name} (similarity: {similarity:.1f}%)\")\n",
    "else:\n",
    "    print(\"\\n✓ No duplicates detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistical Analysis\n",
    "\n",
    "Analyze label distribution and caption characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all labels\n",
    "labels_csv = output_dir / \"all_labels.csv\"\n",
    "\n",
    "if labels_csv.exists():\n",
    "    labels_df = pd.read_csv(labels_csv)\n",
    "    \n",
    "    print(\"Label Distribution Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Analyze each label category\n",
    "    label_cols = [col for col in labels_df.columns if col != 'image_id']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Label Distribution by Category', fontsize=16)\n",
    "    \n",
    "    for idx, col in enumerate(label_cols[:6]):  # Plot first 6 categories\n",
    "        row = idx // 3\n",
    "        col_idx = idx % 3\n",
    "        \n",
    "        # Count values\n",
    "        value_counts = labels_df[col].value_counts()\n",
    "        \n",
    "        # Plot\n",
    "        value_counts.plot(kind='bar', ax=axes[row, col_idx])\n",
    "        axes[row, col_idx].set_title(col.replace('_', ' ').title())\n",
    "        axes[row, col_idx].set_xlabel('')\n",
    "        axes[row, col_idx].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(label_cols), 6):\n",
    "        row = idx // 3\n",
    "        col_idx = idx % 3\n",
    "        axes[row, col_idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nLabel Statistics:\")\n",
    "    for col in label_cols:\n",
    "        print(f\"\\n{col.replace('_', ' ').title()}:\")\n",
    "        print(labels_df[col].value_counts().to_string())\n",
    "else:\n",
    "    print(\"⚠ Labels CSV not found. Please run notebook 04 to generate metadata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caption Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all captions\n",
    "captions_csv = output_dir / \"all_captions.csv\"\n",
    "\n",
    "if captions_csv.exists():\n",
    "    captions_df = pd.read_csv(captions_csv)\n",
    "    \n",
    "    # Calculate caption lengths\n",
    "    captions_df['caption_length'] = captions_df['caption'].str.len()\n",
    "    captions_df['word_count'] = captions_df['caption'].str.split().str.len()\n",
    "    \n",
    "    print(\"Caption Statistics:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total captions: {len(captions_df)}\")\n",
    "    print(f\"\\nCharacter Length:\")\n",
    "    print(f\"  Mean: {captions_df['caption_length'].mean():.1f}\")\n",
    "    print(f\"  Median: {captions_df['caption_length'].median():.1f}\")\n",
    "    print(f\"  Min: {captions_df['caption_length'].min()}\")\n",
    "    print(f\"  Max: {captions_df['caption_length'].max()}\")\n",
    "    print(f\"\\nWord Count:\")\n",
    "    print(f\"  Mean: {captions_df['word_count'].mean():.1f}\")\n",
    "    print(f\"  Median: {captions_df['word_count'].median():.1f}\")\n",
    "    print(f\"  Min: {captions_df['word_count'].min()}\")\n",
    "    print(f\"  Max: {captions_df['word_count'].max()}\")\n",
    "    \n",
    "    # Plot distributions\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    captions_df['caption_length'].hist(bins=20, ax=axes[0])\n",
    "    axes[0].set_title('Caption Length Distribution (characters)')\n",
    "    axes[0].set_xlabel('Characters')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    \n",
    "    captions_df['word_count'].hist(bins=20, ax=axes[1])\n",
    "    axes[1].set_title('Caption Word Count Distribution')\n",
    "    axes[1].set_xlabel('Words')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠ Captions CSV not found. Please run notebook 04 to generate metadata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Human Review Interface\n",
    "\n",
    "Random sample of images for manual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Get all images\n",
    "image_files = list(handler.images_dir.glob(f\"*.{cfg.output['image_format']}\"))\n",
    "\n",
    "# Sample for review (5-10% or minimum 10 images)\n",
    "sample_size = max(10, int(len(image_files) * 0.05))\n",
    "sample_images = random.sample(image_files, min(sample_size, len(image_files)))\n",
    "\n",
    "print(f\"Reviewing {len(sample_images)} randomly sampled images:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create review interface\n",
    "for idx, image_file in enumerate(sample_images, 1):\n",
    "    image_id = image_file.stem\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Review {idx}/{len(sample_images)}: {image_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Load and display image\n",
    "    img = Image.open(image_file)\n",
    "    display(img.resize((512, 512)))\n",
    "    \n",
    "    # Load metadata\n",
    "    metadata = handler.load_metadata(image_id)\n",
    "    if metadata:\n",
    "        print(f\"\\nOriginal Prompt (excerpt):\")\n",
    "        print(f\"  {metadata.get('prompt', 'N/A')[:200]}...\")\n",
    "        print(f\"\\nSource Theme: {metadata.get('source_data', {}).get('atropia', {}).get('theme', 'N/A')}\")\n",
    "    \n",
    "    # Load caption\n",
    "    caption_file = handler.captions_dir / f\"{image_id}_caption.json\"\n",
    "    if caption_file.exists():\n",
    "        with open(caption_file, 'r') as f:\n",
    "            caption_data = json.load(f)\n",
    "        print(f\"\\nGenerated Caption:\")\n",
    "        print(f\"  {caption_data['caption']}\")\n",
    "    \n",
    "    # Load labels\n",
    "    labels_file = handler.labels_dir / f\"{image_id}_labels.json\"\n",
    "    if labels_file.exists():\n",
    "        with open(labels_file, 'r') as f:\n",
    "            labels_data = json.load(f)\n",
    "        print(f\"\\nGenerated Labels:\")\n",
    "        for category, label in labels_data['labels'].items():\n",
    "            print(f\"  {category}: {label}\")\n",
    "    \n",
    "    # Load sample comments\n",
    "    comments_file = handler.comments_dir / f\"{image_id}_comments.json\"\n",
    "    if comments_file.exists():\n",
    "        with open(comments_file, 'r') as f:\n",
    "            comments_data = json.load(f)\n",
    "        print(f\"\\nSample Comments (first 3):\")\n",
    "        for i, comment in enumerate(comments_data['comments'][:3], 1):\n",
    "            print(f\"  {i}. {comment}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Review Checklist\n",
    "\n",
    "For each image reviewed above, consider:\n",
    "- ✓ Image quality and clarity\n",
    "- ✓ Relevance to social movement theme\n",
    "- ✓ Caption accuracy and descriptiveness\n",
    "- ✓ Label appropriateness\n",
    "- ✓ Comment realism and diversity\n",
    "\n",
    "**Note any issues below:**\n",
    "\n",
    "(Space for notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save QA Report\n",
    "\n",
    "Save comprehensive quality assurance report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation report\n",
    "report_path = validator.save_report(validation_report)\n",
    "\n",
    "print(f\"✓ QA report saved to: {report_path}\")\n",
    "print(f\"\\nReport includes:\")\n",
    "print(f\"  - Image validation results\")\n",
    "print(f\"  - Metadata completeness checks\")\n",
    "print(f\"  - Duplicate detection results\")\n",
    "print(f\"  - Overall quality assessment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QUALITY ASSURANCE COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "quality = summary_data['dataset_quality']\n",
    "validation_rate = summary_data['validation_rate']\n",
    "\n",
    "print(f\"\\nOverall Dataset Quality: {quality}\")\n",
    "print(f\"Validation Rate: {validation_rate:.1f}%\")\n",
    "\n",
    "print(\"\\nDataset is ready for:\")\n",
    "if quality in ['Excellent', 'Good']:\n",
    "    print(\"  ✓ Model training and development\")\n",
    "    print(\"  ✓ Semantic similarity analysis\")\n",
    "    print(\"  ✓ Network structure analysis\")\n",
    "    print(\"  ✓ Publication and sharing\")\n",
    "else:\n",
    "    print(\"  ⚠ Review and address issues before proceeding\")\n",
    "    print(\"  ⚠ Consider regenerating problematic images\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Review QA report for detailed findings\")\n",
    "print(\"  2. Address any issues identified\")\n",
    "print(\"  3. Package dataset for Model Development phase\")\n",
    "print(\"  4. Document generation methodology\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Dataset Location: {output_dir}\")\n",
    "print(f\"QA Report: {report_path}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop Complete!\n",
    "\n",
    "Congratulations! You have successfully:\n",
    "\n",
    "1. ✓ Set up and tested the environment\n",
    "2. ✓ Prepared source data from three sources\n",
    "3. ✓ Generated synthetic social movement images\n",
    "4. ✓ Created captions, labels, and comments\n",
    "5. ✓ Validated and assessed dataset quality\n",
    "\n",
    "Your synthetic dataset is ready for the **Model Development** phase of the workshop!\n",
    "\n",
    "### Resources\n",
    "\n",
    "- Dataset: `data/generated/`\n",
    "- QA Report: `data/qa/`\n",
    "- Documentation: `README.md` and `CLAUDE.md`\n",
    "- Support: CyVerse and workshop instructors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
