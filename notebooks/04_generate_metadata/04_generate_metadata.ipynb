{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Metadata (Captions, Labels, Comments)\n",
    "\n",
    "This notebook generates captions, labels, and social media-style comments for all generated images.\n",
    "\n",
    "**Workshop**: AI/ML Pipeline - Synthetic Data Generation  \n",
    "**Date**: January 23, 2026  \n",
    "**Platform**: CyVerse Jupyter Lab PyTorch GPU\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "For each generated image:\n",
    "1. Generates descriptive captions\n",
    "2. Generates semantic and categorical labels  \n",
    "3. Generates social media-style comments\n",
    "4. Saves all metadata with image associations\n",
    "5. Exports CSV summaries for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# Add parent directory to path\n",
    "parent_dir = Path.cwd().parent\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from src import config, gemini_client, output_handler\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Find Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "cfg = config.load_config()\n",
    "\n",
    "# Initialize output handler\n",
    "output_dir = cfg.get_output_path()\n",
    "handler = output_handler.OutputHandler(\n",
    "    output_dir=output_dir,\n",
    "    image_format=cfg.output['image_format'],\n",
    "    metadata_format=cfg.output['metadata_format'],\n",
    "    export_csv=cfg.output['export_csv_summaries']\n",
    ")\n",
    "\n",
    "# Find all generated images\n",
    "image_files = list(handler.images_dir.glob(f\"*.{cfg.output['image_format']}\"))\n",
    "image_files.sort()\n",
    "\n",
    "print(f\"Found {len(image_files)} images to process\")\n",
    "print(f\"Images directory: {handler.images_dir}\")\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    print(\"\\n⚠ No images found! Please run notebook 03_generate_images.ipynb first.\")\n",
    "    raise FileNotFoundError(\"No images to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Text Generator\n",
    "\n",
    "Set up Gemini API client for text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize rate limiter\n",
    "rate_limiter = gemini_client.RateLimiter(\n",
    "    requests_per_minute=cfg.rate_limiting['requests_per_minute'],\n",
    "    requests_per_day=cfg.rate_limiting['requests_per_day']\n",
    ")\n",
    "\n",
    "# Initialize text generator\n",
    "text_generator = gemini_client.GeminiTextGenerator(\n",
    "    api_key=cfg.api_key,\n",
    "    rate_limiter=rate_limiter\n",
    ")\n",
    "\n",
    "print(\"✓ Text generator initialized\")\n",
    "print(f\"  Rate limit: {cfg.rate_limiting['requests_per_minute']} requests/minute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Metadata Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_config = cfg.metadata\n",
    "\n",
    "print(\"Metadata Generation Settings:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Comments per image: {metadata_config['num_comments_per_image']}\")\n",
    "print(f\"Include hashtags: {metadata_config['include_hashtags']}\")\n",
    "print(f\"Include emojis: {metadata_config['include_emojis']}\")\n",
    "print(f\"Label categories: {', '.join(metadata_config['label_categories'])}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Captions\n",
    "\n",
    "Generate descriptive captions for all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating captions...\\n\")\n",
    "\n",
    "caption_errors = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for image_file in tqdm(image_files, desc=\"Captions\"):\n",
    "    try:\n",
    "        # Extract image ID from filename\n",
    "        image_id = image_file.stem\n",
    "        \n",
    "        # Load image\n",
    "        img = Image.open(image_file)\n",
    "        \n",
    "        # Load original metadata for context\n",
    "        original_metadata = handler.load_metadata(image_id)\n",
    "        context = None\n",
    "        if original_metadata:\n",
    "            context = f\"Social movement scene: {original_metadata.get('prompt', '')[:200]}\"\n",
    "        \n",
    "        # Generate caption\n",
    "        caption = text_generator.generate_caption(img, context=context)\n",
    "        \n",
    "        # Save caption\n",
    "        handler.save_caption(\n",
    "            image_id=image_id,\n",
    "            caption=caption,\n",
    "            context={'original_prompt': context}\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        caption_errors += 1\n",
    "        print(f\"\\nError generating caption for {image_file.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n✓ Captions generated: {len(image_files) - caption_errors}/{len(image_files)}\")\n",
    "print(f\"  Time: {int(elapsed//60)}m {int(elapsed%60)}s\")\n",
    "print(f\"  Errors: {caption_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Sample Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "# Get sample captions\n",
    "caption_files = list(handler.captions_dir.glob(\"*_caption.json\"))\n",
    "sample_captions = random.sample(caption_files, min(3, len(caption_files)))\n",
    "\n",
    "print(\"Sample Captions:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for caption_file in sample_captions:\n",
    "    with open(caption_file, 'r') as f:\n",
    "        caption_data = json.load(f)\n",
    "    \n",
    "    print(f\"\\nImage: {caption_data['image_id']}\")\n",
    "    print(f\"Caption: {caption_data['caption']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Labels\n",
    "\n",
    "Generate semantic and categorical labels for all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating labels...\\n\")\n",
    "\n",
    "label_errors = 0\n",
    "start_time = time.time()\n",
    "\n",
    "label_categories = metadata_config['label_categories']\n",
    "\n",
    "for image_file in tqdm(image_files, desc=\"Labels\"):\n",
    "    try:\n",
    "        image_id = image_file.stem\n",
    "        img = Image.open(image_file)\n",
    "        \n",
    "        # Load context\n",
    "        original_metadata = handler.load_metadata(image_id)\n",
    "        context = None\n",
    "        if original_metadata:\n",
    "            context = f\"Social movement context: {original_metadata.get('prompt', '')[:200]}\"\n",
    "        \n",
    "        # Generate labels\n",
    "        labels = text_generator.generate_labels(\n",
    "            img,\n",
    "            categories=label_categories,\n",
    "            context=context\n",
    "        )\n",
    "        \n",
    "        # Save labels\n",
    "        handler.save_labels(\n",
    "            image_id=image_id,\n",
    "            labels=labels,\n",
    "            context={'categories': label_categories}\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        label_errors += 1\n",
    "        print(f\"\\nError generating labels for {image_file.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n✓ Labels generated: {len(image_files) - label_errors}/{len(image_files)}\")\n",
    "print(f\"  Time: {int(elapsed//60)}m {int(elapsed%60)}s\")\n",
    "print(f\"  Errors: {label_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Sample Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample labels\n",
    "label_files = list(handler.labels_dir.glob(\"*_labels.json\"))\n",
    "sample_labels = random.sample(label_files, min(3, len(label_files)))\n",
    "\n",
    "print(\"Sample Labels:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for label_file in sample_labels:\n",
    "    with open(label_file, 'r') as f:\n",
    "        label_data = json.load(f)\n",
    "    \n",
    "    print(f\"\\nImage: {label_data['image_id']}\")\n",
    "    print(\"Labels:\")\n",
    "    for category, label in label_data['labels'].items():\n",
    "        print(f\"  {category}: {label}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Comments\n",
    "\n",
    "Generate social media-style comments for all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating comments...\\n\")\n",
    "\n",
    "comment_errors = 0\n",
    "start_time = time.time()\n",
    "\n",
    "num_comments = metadata_config['num_comments_per_image']\n",
    "include_hashtags = metadata_config['include_hashtags']\n",
    "include_emojis = metadata_config['include_emojis']\n",
    "\n",
    "for image_file in tqdm(image_files, desc=\"Comments\"):\n",
    "    try:\n",
    "        image_id = image_file.stem\n",
    "        img = Image.open(image_file)\n",
    "        \n",
    "        # Load context\n",
    "        original_metadata = handler.load_metadata(image_id)\n",
    "        context = None\n",
    "        if original_metadata:\n",
    "            context = f\"Social movement image. Theme: {original_metadata.get('source_data', {}).get('atropia', {}).get('theme', 'civic engagement')}\"\n",
    "        \n",
    "        # Generate comments\n",
    "        comments = text_generator.generate_comments(\n",
    "            img,\n",
    "            num_comments=num_comments,\n",
    "            include_hashtags=include_hashtags,\n",
    "            include_emojis=include_emojis,\n",
    "            context=context\n",
    "        )\n",
    "        \n",
    "        # Save comments\n",
    "        handler.save_comments(\n",
    "            image_id=image_id,\n",
    "            comments=comments,\n",
    "            context={'num_requested': num_comments}\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        comment_errors += 1\n",
    "        print(f\"\\nError generating comments for {image_file.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n✓ Comments generated: {len(image_files) - comment_errors}/{len(image_files)}\")\n",
    "print(f\"  Time: {int(elapsed//60)}m {int(elapsed%60)}s\")\n",
    "print(f\"  Errors: {comment_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Sample Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample comments\n",
    "comment_files = list(handler.comments_dir.glob(\"*_comments.json\"))\n",
    "sample_comments = random.sample(comment_files, min(3, len(comment_files)))\n",
    "\n",
    "print(\"Sample Comments:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for comment_file in sample_comments:\n",
    "    with open(comment_file, 'r') as f:\n",
    "        comment_data = json.load(f)\n",
    "    \n",
    "    print(f\"\\nImage: {comment_data['image_id']}\")\n",
    "    print(\"Comments:\")\n",
    "    for i, comment in enumerate(comment_data['comments'], 1):\n",
    "        print(f\"  {i}. {comment}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export CSV Summaries\n",
    "\n",
    "Export all metadata to CSV files for easy analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exporting CSV summaries...\\n\")\n",
    "\n",
    "# Export captions\n",
    "captions_csv = handler.export_captions_csv()\n",
    "if captions_csv:\n",
    "    print(f\"✓ Captions exported to: {captions_csv}\")\n",
    "\n",
    "# Export labels\n",
    "labels_csv = handler.export_labels_csv()\n",
    "if labels_csv:\n",
    "    print(f\"✓ Labels exported to: {labels_csv}\")\n",
    "\n",
    "# Export comments\n",
    "comments_csv = handler.export_comments_csv()\n",
    "if comments_csv:\n",
    "    print(f\"✓ Comments exported to: {comments_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Check Completeness\n",
    "\n",
    "Verify all images have complete metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness = handler.check_completeness()\n",
    "\n",
    "print(\"\\nDataset Completeness Check:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total images: {completeness['total_images']}\")\n",
    "print(f\"\\nMetadata Coverage:\")\n",
    "print(f\"  Captions: {completeness['images_with_captions']} ({completeness['caption_coverage']:.1f}%)\")\n",
    "print(f\"  Labels: {completeness['images_with_labels']} ({completeness['label_coverage']:.1f}%)\")\n",
    "print(f\"  Comments: {completeness['images_with_comments']} ({completeness['comment_coverage']:.1f}%)\")\n",
    "\n",
    "if completeness['fully_complete']:\n",
    "    print(\"\\n✓ Dataset is fully complete! All images have all metadata.\")\n",
    "else:\n",
    "    print(\"\\n⚠ Some images are missing metadata. Check errors above.\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Metadata generation complete! Your dataset now includes:\n",
    "- Descriptive captions for each image\n",
    "- Semantic and categorical labels\n",
    "- Social media-style comments\n",
    "- CSV exports for easy analysis\n",
    "\n",
    "**Next Step**: Run notebook `05_quality_assurance.ipynb` to validate the complete dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
